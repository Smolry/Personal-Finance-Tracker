{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Finance Tracker - ML Pipeline\n",
    "\n",
    "## Transaction Categorization using Machine Learning\n",
    "\n",
    "**Author:** Aniket Behera  \n",
    "**Goal:** Build an ML model to automatically categorize financial transactions\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline Overview:\n",
    "1. **Data Generation & Exploration**\n",
    "2. **Feature Engineering**\n",
    "3. **Model Selection & Training**\n",
    "4. **Hyperparameter Tuning**\n",
    "5. **Evaluation & Analysis**\n",
    "6. **Deployment Considerations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation & Exploration\n",
    "\n",
    "We generate synthetic transaction data that mimics real-world patterns:\n",
    "- 1600+ transactions over 12 months\n",
    "- 12 categories (Dining, Groceries, Utilities, etc.)\n",
    "- Includes recurring transactions (subscriptions, bills, salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('large_transactions.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar plot\n",
    "category_counts = df['category'].value_counts()\n",
    "category_counts.plot(kind='bar', ax=ax1, color='steelblue', alpha=0.8)\n",
    "ax1.set_title('Transaction Distribution by Category', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Category')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Pie chart\n",
    "category_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Category Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNumber of categories: {df['category'].nunique()}\")\n",
    "print(f\"Most common category: {category_counts.index[0]} ({category_counts.values[0]} transactions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample transactions per category\n",
    "print(\"Sample transactions from each category:\\n\")\n",
    "for category in sorted(df['category'].unique()):\n",
    "    samples = df[df['category'] == category]['description'].sample(min(3, len(df[df['category'] == category]))).tolist()\n",
    "    print(f\"{category:20s}: {', '.join(samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "**Why TF-IDF?**\n",
    "- Transaction descriptions are text data\n",
    "- TF-IDF converts text to numerical features\n",
    "- Captures importance of words across categories\n",
    "- Using bi-grams (1,2) captures phrases like \"gas station\" not just \"gas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore TF-IDF features\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=50)\n",
    "X_sample = vectorizer.fit_transform(df['description'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"Number of features extracted: {len(feature_names)}\")\n",
    "print(f\"\\nTop 20 features (words/phrases):\")\n",
    "print(feature_names[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Selection & Training\n",
    "\n",
    "**Why Random Forest?**\n",
    "1. Handles high-dimensional sparse data (TF-IDF features) well\n",
    "2. Robust to overfitting with proper parameters\n",
    "3. Provides feature importance (which words matter most)\n",
    "4. No need for feature scaling\n",
    "5. Works well with imbalanced classes\n",
    "\n",
    "**Alternatives considered:**\n",
    "- Naive Bayes: Too simple, assumes feature independence\n",
    "- Logistic Regression: Linear, may miss complex patterns\n",
    "- SVM: Slower, harder to interpret\n",
    "- Neural Networks: Overkill for this dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df['description']\n",
    "y = df['category']\n",
    "\n",
    "# Train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create baseline model\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_df=0.95)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"Training baseline model...\")\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate baseline\n",
    "y_pred_baseline = baseline_pipeline.predict(X_test)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"✓ Baseline model trained\")\n",
    "print(f\"  Baseline accuracy: {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning\n",
    "\n",
    "Using GridSearchCV to find optimal parameters:\n",
    "- `ngram_range`: Should we use single words or phrases?\n",
    "- `max_features`: How many features to keep?\n",
    "- `n_estimators`: Number of trees in forest\n",
    "- `max_depth`: How deep should trees grow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_features': [300, 500],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [15, 20, None],\n",
    "    'clf__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(f\"Total combinations to test: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "print(\"\\nStarting grid search (this may take a few minutes)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    baseline_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n✓ Grid search complete\")\n",
    "print(f\"\\nBest parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest cross-validation F1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Analysis\n",
    "\n",
    "Comprehensive evaluation using multiple metrics:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: Of predicted category X, how many were actually X?\n",
    "- **Recall**: Of all actual category X transactions, how many did we catch?\n",
    "- **F1 Score**: Harmonic mean of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_train, best_model.predict(X_train))\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"  Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"  Test accuracy:     {test_accuracy:.4f}\")\n",
    "print(f\"  Overfitting gap:   {(train_accuracy - test_accuracy):.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "print(f\"\\n5-Fold CV F1 Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nPer-Category Performance:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "categories = sorted(y_test.unique())\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=categories, yticklabels=categories,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Transaction Categorization', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Category', fontsize=12)\n",
    "plt.xlabel('Predicted Category', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Diagonal values (correct predictions) should be highest\")\n",
    "print(\"- Off-diagonal values show misclassifications\")\n",
    "print(\"- Can identify which categories are confused with each other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "vectorizer = best_model.named_steps['tfidf']\n",
    "classifier = best_model.named_steps['clf']\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "importances = classifier.feature_importances_\n",
    "\n",
    "# Get top 20 features\n",
    "top_indices = np.argsort(importances)[-20:][::-1]\n",
    "top_features = [(feature_names[i], importances[i]) for i in top_indices]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "features, scores = zip(*top_features)\n",
    "plt.barh(range(len(features)), scores, color='steelblue', alpha=0.8)\n",
    "plt.yticks(range(len(features)), features)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Top 20 Most Important Features (Keywords)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMost important keywords for categorization:\")\n",
    "for feature, score in top_features[:10]:\n",
    "    print(f\"  {feature:30s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-World Testing & Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on unseen examples\n",
    "test_transactions = [\n",
    "    \"Starbucks Coffee Shop\",\n",
    "    \"Walmart Grocery Store\",\n",
    "    \"Netflix Monthly Subscription\",\n",
    "    \"Uber Ride to Airport\",\n",
    "    \"Paycheck Deposit\",\n",
    "    \"CVS Pharmacy Medicine\",\n",
    "    \"Delta Airlines Flight Ticket\",\n",
    "    \"Rent Payment Apartment\",\n",
    "    \"Amazon Online Shopping\",\n",
    "    \"Gas Station Fill-up\"\n",
    "]\n",
    "\n",
    "predictions = best_model.predict(test_transactions)\n",
    "probabilities = best_model.predict_proba(test_transactions)\n",
    "confidences = np.max(probabilities, axis=1)\n",
    "\n",
    "print(\"Predictions on unseen transactions:\\n\")\n",
    "print(f\"{'Description':<35} {'Predicted Category':<20} {'Confidence'}\")\n",
    "print(\"=\"*75)\n",
    "for desc, pred, conf in zip(test_transactions, predictions, confidences):\n",
    "    print(f\"{desc:<35} {pred:<20} {conf:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis - find misclassifications\n",
    "errors = X_test[y_test != y_pred]\n",
    "true_labels = y_test[y_test != y_pred]\n",
    "pred_labels = pd.Series(y_pred, index=y_test.index)[y_test != y_pred]\n",
    "\n",
    "print(f\"\\nMisclassified transactions: {len(errors)} out of {len(y_test)} ({len(errors)/len(y_test):.1%})\")\n",
    "print(\"\\nSample misclassifications:\")\n",
    "print(f\"{'Transaction':<40} {'True':<15} {'Predicted':<15}\")\n",
    "print(\"=\"*75)\n",
    "for i, (desc, true, pred) in enumerate(zip(errors[:10], true_labels[:10], pred_labels[:10])):\n",
    "    print(f\"{desc:<40} {true:<15} {pred:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deployment Considerations\n",
    "\n",
    "**Production Readiness:**\n",
    "1. ✓ Model versioning implemented\n",
    "2. ✓ Metrics tracking for each version\n",
    "3. ✓ Fallback to rule-based categorization\n",
    "4. ✓ Confidence scores for active learning\n",
    "\n",
    "**Future Improvements:**\n",
    "- Implement model retraining pipeline (monthly)\n",
    "- Add drift detection\n",
    "- Upgrade to transformer models (BERT/DistilBERT)\n",
    "- Add anomaly detection for fraud\n",
    "- A/B testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model Type:           Random Forest Classifier\")\n",
    "print(f\"Feature Engineering:  TF-IDF with bi-grams\")\n",
    "print(f\"Training Data:        {len(X_train)} transactions\")\n",
    "print(f\"Categories:           {len(categories)}\")\n",
    "print(f\"Test Accuracy:        {test_accuracy:.4f}\")\n",
    "print(f\"CV F1 Score:          {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "print(f\"Best Parameters:      {grid_search.best_params_}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
